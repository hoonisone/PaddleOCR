{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split (EASY, HARD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files = {\n",
    "    \"train\": [\"/home/labelsets/aihub_rec_full_horizontal_clean_80:10:10/train_label.txt\"],\n",
    "    \"eval\": [\"/home/labelsets/aihub_rec_full_horizontal_clean_80:10:10/eval_label.txt\"],\n",
    "    \"test\": [\"/home/labelsets/aihub_rec_full_horizontal_clean_80:10:10/test_label.txt\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_label(label_files):\n",
    "    labels = list()\n",
    "    for file in label_files:\n",
    "        with open(file, \"r\") as f:\n",
    "            labels = [line.rstrip().split(\"\\t\") for line in f.readlines()]\n",
    "    return labels\n",
    "\n",
    "\n",
    "# {task: labels}\n",
    "labels_dict = {name: load_label(files) for name, files in label_files.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 1741\n",
      "eval: 1353\n",
      "test: 1357\n",
      "train & eval = 1328 | train - eval = 413 | eval - train = 25\n",
      "train & test = 1335 | train - test = 406 | test - train = 22\n",
      "eval & test = 1221 | eval - test = 132 | test - eval = 136\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "def get_char_set_from_labels(labels):\n",
    "    char_set = set()\n",
    "    for label in labels:\n",
    "        char_set.update(set(label[1]))\n",
    "    return char_set\n",
    "\n",
    "char_set_dict = {task: get_char_set_from_labels(labels) for task, labels in labels_dict.items()}\n",
    "\n",
    "for task, char_set in char_set_dict.items():\n",
    "    print(f\"{task}: {len(char_set)}\")\n",
    "    \n",
    "task_combinations = list(itertools.combinations(list(char_set_dict.keys()), 2))\n",
    "for task1, task2 in task_combinations: # 각 task 조합에 대해 정보 출력\n",
    "    print(f\"{task1} & {task2} = {len(char_set_dict[task1] & char_set_dict[task2])} | {task1} - {task2} = {len(char_set_dict[task1] - char_set_dict[task2])} | {task2} - {task1} = {len(char_set_dict[task2] - char_set_dict[task1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_num_report(labels):\n",
    "    report = {}\n",
    "    for label in labels:\n",
    "        for char in label[1]:\n",
    "            if char not in report:\n",
    "                report[char] = 0\n",
    "            report[char] += 1\n",
    "    return dict(sorted(report.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "\n",
    "char_num_report_dict = {task: char_num_report(labels) for task, labels in labels_dict.items()}\n",
    "# char_num_report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train, many): 257\n",
      "(train, medium): 529\n",
      "(train, few): 955\n",
      "\n",
      "(eval, many): 37\n",
      "(eval, medium): 329\n",
      "(eval, few): 987\n",
      "\n",
      "(test, many): 35\n",
      "(test, medium): 338\n",
      "(test, few): 984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def easy_hard(sample):\n",
    "    char, num = sample\n",
    "    if 1500 <= num  :\n",
    "        return \"many\"\n",
    "    elif 100 <= num:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"few\"\n",
    "\n",
    "def get_easy_hard_report_dict(char_num_report_dict):\n",
    "    easy_hard_report = dict()\n",
    "    for split, num_report in char_num_report_dict.items():\n",
    "        easy_hard_sub_report = {}\n",
    "        for sample in num_report.items():\n",
    "            easy_hard_sub_report.setdefault(easy_hard(sample), []).append(sample[0])\n",
    "        easy_hard_report[split]=easy_hard_sub_report\n",
    "    return easy_hard_report\n",
    "\n",
    "many_few_char_set_dict = get_easy_hard_report_dict(char_num_report_dict)\n",
    "\n",
    "for task, report in many_few_char_set_dict.items():\n",
    "    for easy_hard, samples in report.items():\n",
    "        print(f\"({task}, {easy_hard}): {len(samples)}\")\n",
    "    print()\n",
    "    \n",
    "# train을 제외하면 many, medium, few 등이 의미가 없다고 보면 될 듯\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_with_char_set(labels, char_set):\n",
    "    report = {\n",
    "        \"used\": [],\n",
    "        \"unused\": []\n",
    "    }\n",
    "    \n",
    "    for img_path, label in labels:\n",
    "        if len(set(label) & set(char_set)) == 0:\n",
    "            report[\"unused\"].append((img_path, label))\n",
    "        else:\n",
    "            report[\"used\"].append((img_path, label))\n",
    "    return report\n",
    "\n",
    "\n",
    "def get_task_level_sample_dict(many_few_char_set_dict, char_set_dict, labels_dict, criterion = \"train\"):\n",
    "    report = dict()\n",
    "    \n",
    "    many = many_few_char_set_dict[criterion][\"many\"]\n",
    "    medium = many_few_char_set_dict[criterion][\"medium\"]\n",
    "    few = many_few_char_set_dict[criterion][\"few\"]\n",
    "    \n",
    "    \n",
    "    for task, char_set in char_set_dict.items():\n",
    "        if task == criterion:\n",
    "            continue\n",
    "        \n",
    "        unseen = char_set_dict[task] - char_set_dict[criterion]\n",
    "        \n",
    "        report[task] = dict()\n",
    "        \n",
    "        use_report = get_split_with_char_set(labels_dict[task], unseen)\n",
    "        report[task][\"unseen\"] = use_report[\"used\"]\n",
    "        \n",
    "        use_report = get_split_with_char_set(use_report[\"unused\"], few)\n",
    "        report[task][\"hard\"] = use_report[\"used\"]\n",
    "        \n",
    "        use_report = get_split_with_char_set(use_report[\"unused\"], medium)\n",
    "        report[task][\"normal\"] = use_report[\"used\"]\n",
    "        report[task][\"easy\"] = use_report[\"unused\"]\n",
    "        \n",
    "        \n",
    "        # report[task][\"hard\"] = get_split_with_char_set(labels_dict[task], few)[\"used\"]\n",
    "        # report[task][\"easy\"] = get_split_with_char_set(labels_dict[task], few+medium)[\"unused\"]\n",
    "        # report[task][\"normal\"] = get_split_with_char_set(labels_dict[task], few)[\"unused\"]\n",
    "        \n",
    "        \n",
    "    return report\n",
    "\n",
    "# task별 level 별 sample\n",
    "task_level_sample_dict = get_task_level_sample_dict(many_few_char_set_dict, char_set_dict, labels_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(eval, unseen): 27\n",
      "(eval, hard): 2139\n",
      "(eval, normal): 24586\n",
      "(eval, easy): 36831\n",
      "\n",
      "(test, unseen): 22\n",
      "(test, hard): 2211\n",
      "(test, normal): 24278\n",
      "(test, easy): 37073\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for task, report in task_level_sample_dict.items():\n",
    "    for easy_hard, samples in report.items():\n",
    "        print(f\"({task}, {easy_hard}): {len(samples)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "from pathlib import Path\n",
    "\n",
    "dir_path = Path(\"/home/test_dataset\")\n",
    "dir_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for task, level_sample_dict in task_level_sample_dict.items():\n",
    "    for level, samples in level_sample_dict.items():\n",
    "        file_path = dir_path/task/level/\"label.txt\"\n",
    "        file_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            for img_path, label in samples:\n",
    "                f.write(f\"{img_path}\\t{label}\\n\")\n",
    "                \n",
    "        file_path = dir_path/task/level/\"infer.txt\"\n",
    "        file_path.parent.mkdir(exist_ok=True, parents=True)\n",
    "        with open(file_path, \"w\") as f:\n",
    "            for img_path, label in samples:\n",
    "                f.write(f\"{img_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used 26736\n",
      "unused 36847\n"
     ]
    }
   ],
   "source": [
    "eval_report = get_split_with_char_set(eval_labels, train_medium+train_few)\n",
    "for k, v in eval_report.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
