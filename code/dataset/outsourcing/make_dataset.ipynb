{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "from tools import polygon_utility\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "    def __init__(self):\n",
    "        self.on = True\n",
    "    \n",
    "    def print(self, text):\n",
    "        if self.on:\n",
    "            print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_without_rotation(path):\n",
    "    img = Image.open(path)\n",
    "    exif = img._getexif()\n",
    "\n",
    "    if exif:\n",
    "        orientation = exif.get(0x0112)\n",
    "        if orientation == 3:\n",
    "            img = img.rotate(180, expand=True)\n",
    "        elif orientation == 6:\n",
    "            img = img.rotate(270, expand=True)\n",
    "        elif orientation == 8:\n",
    "            img = img.rotate(90, expand=True)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_without_rotation(path):\n",
    "    img = Image.open(path)\n",
    "    exif = img._getexif()\n",
    "\n",
    "    if exif:\n",
    "        orientation = exif.get(0x0112)\n",
    "        if orientation == 3:\n",
    "            img = img.rotate(180, expand=True)\n",
    "        elif orientation == 6:\n",
    "            img = img.rotate(270, expand=True)\n",
    "        elif orientation == 8:\n",
    "            img = img.rotate(90, expand=True)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def load_ppocrlabel(path,\n",
    "                    label_file_name = \"Label.txt\",\n",
    "                    deprecated_labels = [\"(한자)\", \"((한자))\", \"(((한자)))\", \"(일본어)\", \"((일본어))\", \"(((일본어)))\", \"(외국어)\",\"((외국어))\",\"(((외국어)))\",  \"(영어)\", \"((영어))\", \"(((영어)))\"],\n",
    "                    only_internal_text_label = True,\n",
    "                    print_log = False\n",
    "                    ):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        path (str): ppocrlabel 프로그램을 사용해 만든 레이블 파일의 경로\n",
    "        deprecated_labels (list): 안쓰는 레이블 리스트 (삭제됨)\n",
    "        only_internal_text_label (bool): 모든 텍스트가 간판 내에만 있는지 확인하고 그렇지 않은 이미지는 제외\n",
    "        print_log (bool): 진행 상황 로그를 출력할 지 여부\n",
    "        \n",
    "    Returns:\n",
    "        list: 레이블 정보를 로드하여 리스트 형태로 반환\n",
    "        \n",
    "        result = [image_label, ...]\n",
    "        image_label = {\"sign\":label, \"text\":[label, ...]}\n",
    "        label = {\"transcription\":str , \"points\": polygon}\n",
    "        polygon: [(x1, y1), (x2, y2), ... , (xn, yn)]\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    logger = Logger()\n",
    "    \n",
    "    logger.on = print_log\n",
    "    \n",
    "    \n",
    "    # 데이터 로드\n",
    "    lable_file_path = Path(path)/label_file_name\n",
    "    def load_data(path):\n",
    "        with open(path) as f:\n",
    "            lines = [line.rstrip(\"\\n\") for line in f.readlines()]\n",
    "        return lines\n",
    "    logger.print(\"Load all data\")\n",
    "    lines = load_data(lable_file_path)\n",
    "    logger.print(\"\\n\")\n",
    "\n",
    "\n",
    "    # 각 줄을 샘플로 변환\n",
    "    def line_to_sample(line):\n",
    "        image_path, labels = line.split(\"\\t\")\n",
    "        labels = json.loads(labels)\n",
    "        return {\"image_path\":image_path, \"labels\": labels}\n",
    "    logger.print(\"Convert text data into sample data\")\n",
    "    samples = [line_to_sample(line) for line in lines]\n",
    "    logger.print(\"\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 이미지가 존재하지 않는 샘플이 있는지 확인\n",
    "    def check_image_exist(samples):\n",
    "        remove_num = 0\n",
    "        new_samples = []\n",
    "        for sample in samples:\n",
    "            image_path = Path(path)/sample[\"image_path\"]\n",
    "            if not image_path.exists():\n",
    "                remove_num += 1\n",
    "                logger.print(f\"Removed {sample['image_path']}\")\n",
    "            else:\n",
    "                new_samples.append(sample)\n",
    "        return new_samples, remove_num\n",
    "    \n",
    "    logger.print(\"Check the label has valid image path\")\n",
    "    samples, remove_num = check_image_exist(samples)\n",
    "    logger.print(f\"\\tTotal {remove_num} of samples was removed for having no image \\n\")\n",
    "    \n",
    "    # 간판과 텍스트 레이블 구분\n",
    "    def devide_sign_and_text(sample):\n",
    "        sign_labels, text_labels = [], []\n",
    "        for label in sample[\"labels\"]:\n",
    "            if label[\"transcription\"] in [\"@@@\", \"###\", \"@@@@\", \"####\"]:\n",
    "                sign_labels.append(label)\n",
    "            else:\n",
    "                text_labels.append(label)\n",
    "        return {\"image_path\":sample[\"image_path\"], \"sign_labels\":sign_labels, \"text_labels\":text_labels}\n",
    "    logger.print(\"Distingush sign and test label\")\n",
    "    samples = [devide_sign_and_text(sample) for sample in samples]\n",
    "    logger.print(\"\\n\")\n",
    "\n",
    "    # 모든 텍스트가 간판 안에 있는 이미지 외에 제거\n",
    "    def remain_only_internal_samples(samples):\n",
    "        remove_num = 0\n",
    "        new_samples = []\n",
    "        for sample in samples:\n",
    "            if not all([any([polygon_utility.is_polygon_inside_polygon(text_label[\"points\"], sign_label[\"points\"]) for sign_label in sample[\"sign_labels\"]]) for text_label in sample[\"text_labels\"]]):\n",
    "                remove_num += 1\n",
    "                logger.print(f\"유효하지 않아 제거됨: {sample['image_path']}\")\n",
    "            else:\n",
    "                new_samples.append(sample)\n",
    "        return samples, remove_num\n",
    "\n",
    "    if only_internal_text_label:\n",
    "        logger.print(\"Check and remove the images whose all text labels are included in the sign label\")\n",
    "        samples, remove_num = remain_only_internal_samples(samples)\n",
    "        logger.print(f\"\\t{remove_num} of images were removed for including one more not included text lable\\n\")\n",
    "        \n",
    "\n",
    "    # 제거할 텍스트 레이블 제거\n",
    "    def remove_target_label(samples):\n",
    "        remove_num = 0\n",
    "        samples = samples.copy()\n",
    "        for sample in samples:\n",
    "            text_labels = []\n",
    "            for text_label in sample[\"text_labels\"]:\n",
    "                # 제거할 텍스트 레이블 제거\n",
    "                if text_label[\"transcription\"] in deprecated_labels:\n",
    "                    logger.print(f\"Removed {text_label}\")\n",
    "                    remove_num += 1\n",
    "                else:\n",
    "                    text_labels.append(text_label)\n",
    "            sample[\"text_labels\"] = text_labels\n",
    "        return samples, remove_num\n",
    "        \n",
    "    if deprecated_labels is not None:\n",
    "        logger.print(\"Remove the invalid text labels\")\n",
    "        samples, remove_num = remove_target_label(samples)\n",
    "        logger.print(f\"\\t{remove_num} of text labels were removed\\n\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    def group_sign_and_text_lables(samples):\n",
    "        samples = samples.copy()\n",
    "        for sample in samples:\n",
    "            sign_and_text_labels = []        \n",
    "            for sign_label in sample[\"sign_labels\"]:\n",
    "                sign_text_labels = []\n",
    "                for text_label in sample[\"text_labels\"]:\n",
    "                    if polygon_utility.is_polygon_inside_polygon(text_label[\"points\"], sign_label[\"points\"]):\n",
    "                        sign_text_labels.append(text_label)\n",
    "                \n",
    "                sign_and_text_labels.append({\"sign\":sign_label, \"text\":sign_text_labels}) \n",
    "            del sample[\"sign_labels\"]\n",
    "            del sample[\"text_labels\"]\n",
    "            sample[\"labels\"] =  sign_and_text_labels\n",
    "        return samples\n",
    "    logger.print(\"Group sign and internal text labels\")\n",
    "    samples = group_sign_and_text_lables(samples)\n",
    "    logger.print(\"\\n\")\n",
    "    \n",
    "    logger.print(f\"Total image labels: {len(samples)}\")\n",
    "    logger.print(f\"Total sign labels: {sum([len(sample['labels']) for sample in samples])}\")\n",
    "    logger.print(f\"Total text labels: {sum([sum([len(label['text']) for label in sample['labels']]) for sample in samples])}\")\n",
    "    return samples\n",
    "\n",
    "def make_and_save_detection_dataset(label_dir, samples, save_dir, dir_size=1000, label_file_name = \"label.txt\"):\n",
    "    samples = copy.deepcopy(samples)\n",
    "    assert not save_dir.exists(), f\"please remove {save_dir}\"\n",
    "    label_path = save_dir/label_file_name\n",
    "    image_idx = 0\n",
    "\n",
    "    for sample in samples:  \n",
    "        image_path, labels = sample[\"image_path\"], sample[\"labels\"]  \n",
    "        image = load_image_without_rotation(label_dir/image_path)\n",
    "        for label in labels:\n",
    "            sign_label = label[\"sign\"]\n",
    "            text_labels = label[\"text\"]\n",
    "            \n",
    "            # 각 좌표를 잘린 이미지에 따라 pranslate\n",
    "            min_x = min([x for x, y in  sign_label[\"points\"]])\n",
    "            min_y = min([y for x, y in  sign_label[\"points\"]])\n",
    "            for i in range(len(text_labels)):\n",
    "                text_labels[i][\"points\"] = [[x-min_x, y-min_y] for x, y in text_labels[i][\"points\"]]\n",
    "            \n",
    "            cropped_image = polygon_utility.crop_by_polygon(image, sign_label[\"points\"])\n",
    "            image_path = save_dir/f\"{(image_idx//dir_size + 1)}\"/f\"{image_idx+1}.png\"\n",
    "            image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            cropped_image.save(image_path)\n",
    "            with open(label_path, \"a\") as f:\n",
    "                image_file = str(image_path.relative_to(save_dir)).replace('\\\\', '/')\n",
    "                f.write(f\"{image_file}\\t{json.dumps(text_labels, ensure_ascii=False)}\\n\")\n",
    "\n",
    "            image_idx += 1\n",
    "\n",
    "def make_and_save_recognition_dataset(label_dir, samples, save_dir, dir_size=1000, label_file_name = \"label.txt\", deprecated_labels = [\"xxx\", \"xxxx\", \"XXX\", \"XXXX\"], print_log = False):\n",
    "    assert not save_dir.exists(), f\"please remove {save_dir}\"\n",
    "    \n",
    "    logger = Logger()\n",
    "    logger.on = print_log\n",
    "    \n",
    "    label_path = save_dir/label_file_name\n",
    "    image_idx = 0\n",
    "    removed_num = 0\n",
    "    saved_num = 0\n",
    "    for sample in samples:  \n",
    "        image_path, labels = sample[\"image_path\"], sample[\"labels\"]\n",
    "         \n",
    "        image = load_image_without_rotation(label_dir/image_path)\n",
    "        for label in labels:\n",
    "            sign_label = label[\"sign\"]\n",
    "            text_labels = label[\"text\"]\n",
    "        \n",
    "            \n",
    "            for text_label in text_labels:\n",
    "                if text_label[\"transcription\"] in deprecated_labels:\n",
    "                    removed_num += 1\n",
    "                    logger.print(f\"Pass {text_label}\")\n",
    "                    continue\n",
    "                else:\n",
    "                    saved_num += 1\n",
    "                \n",
    "                cropped_image = polygon_utility.crop_by_polygon(image, text_label[\"points\"])\n",
    "                image_path = save_dir/f\"{(image_idx//dir_size + 1)}\"/f\"{image_idx+1}.png\"\n",
    "                image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                cropped_image.save(image_path)\n",
    "                with open(label_path, \"a\") as f:\n",
    "                    image_file = str(image_path.relative_to(save_dir)).replace('\\\\', '/')\n",
    "                    f.write(f\"{image_file}\\t{text_label['transcription']}\\n\")\n",
    "\n",
    "                image_idx += 1\n",
    "    logger.print(f\"Total {saved_num+removed_num}\")\n",
    "    logger.print(f\"Removed {removed_num}\")\n",
    "    logger.print(f\"Saved {saved_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load all data\n",
      "\n",
      "\n",
      "Convert text data into sample data\n",
      "\n",
      "\n",
      "Check the label has valid image path\n",
      "\tTotal 0 of samples was removed for having no image \n",
      "\n",
      "Distingush sign and test label\n",
      "\n",
      "\n",
      "Check and remove the images whose all text labels are included in the sign label\n",
      "\t0 of images were removed for including one more not included text lable\n",
      "\n",
      "Remove the invalid text labels\n",
      "Removed {'transcription': '(한자)', 'points': [[2085, 1277], [2223, 1277], [2223, 1407], [2085, 1407]], 'difficult': False}\n",
      "Removed {'transcription': '(한자)', 'points': [[911, 1372], [1040, 1372], [1040, 1397], [911, 1397]], 'difficult': False}\n",
      "Removed {'transcription': '(한자)', 'points': [[1659, 2073], [1725, 2073], [1725, 2122], [1659, 2122]], 'difficult': False}\n",
      "Removed {'transcription': '(한자)', 'points': [[2053, 1368], [2082, 1368], [2082, 1409], [2053, 1409]], 'difficult': False}\n",
      "\t4 of text labels were removed\n",
      "\n",
      "Group sign and internal text labels\n",
      "\n",
      "\n",
      "Total image labels: 27\n",
      "Total sign labels: 52\n",
      "Total text labels: 107\n",
      "Total 107\n",
      "Removed 0\n",
      "Saved 107\n"
     ]
    }
   ],
   "source": [
    "names = [\n",
    "    # \"outsourcing_v1\",\n",
    "    # \"outsourcing_v1(exception)\",\n",
    "    # \"outsourcing_v2.1\",\n",
    "    # \"outsourcing_v2.1(exception)\",\n",
    "    # \"outsourcing_v2.2\",\n",
    "    # \"outsourcing_v2.2(exception)\",    \n",
    "    # \"outsourcing_v2.3\",\n",
    "    # \"outsourcing_v2.3(exception)\",\n",
    "    # \"outsourcing_v2.4\",\n",
    "    # \"outsourcing_v2.4(exception)\",\n",
    "    # \"outsourcing_v2.5\",\n",
    "    # \"outsourcing_v2.5(exception)\",\n",
    "    # \"outsourcing_v2.6.1\",\n",
    "    # \"outsourcing_v2.6.1(exception)\",\n",
    "    # \"outsourcing_v2.6.2\",\n",
    "    # \"outsourcing_v2.6.2(exception)\"\n",
    "    \"240425_세종_정면_간판_레이블링\"\n",
    "]\n",
    "for name in names:\n",
    "    # label_dir = Path(f\"/home/origin_datasets/{name}\")\n",
    "    label_dir = Path(f\"/home/resources/{name}/\")\n",
    "    std_result_path = f\"/home/resources/{name}_det\"\n",
    "    str_result_path = f\"/home/resources/{name}_rec\"\n",
    "\n",
    "    samples = load_ppocrlabel(label_dir, print_log=True, label_file_name=\"Label.txt\")\n",
    "    make_and_save_detection_dataset(label_dir, samples, Path(std_result_path))\n",
    "    make_and_save_recognition_dataset(label_dir, samples, Path(str_result_path), print_log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': '0.jpg',\n",
       " 'labels': [{'sign': {'transcription': '@@@',\n",
       "    'points': [[894, 1153], [2594, 1153], [2594, 1524], [894, 1524]],\n",
       "    'difficult': False},\n",
       "   'text': [{'transcription': '금강시티타워',\n",
       "     'points': [[100, 20], [1616, 20], [1616, 326], [100, 326]],\n",
       "     'difficult': False}]},\n",
       "  {'sign': {'transcription': '###',\n",
       "    'points': [[613, 1089],\n",
       "     [565, 1083],\n",
       "     [533, 1105],\n",
       "     [487, 1147],\n",
       "     [475, 1173],\n",
       "     [471, 1286],\n",
       "     [468, 1334],\n",
       "     [491, 1447],\n",
       "     [504, 1486],\n",
       "     [510, 1537],\n",
       "     [529, 1579],\n",
       "     [552, 1602],\n",
       "     [578, 1625],\n",
       "     [600, 1631],\n",
       "     [626, 1605],\n",
       "     [642, 1589],\n",
       "     [668, 1544],\n",
       "     [687, 1518],\n",
       "     [687, 1483],\n",
       "     [700, 1441],\n",
       "     [704, 1389],\n",
       "     [710, 1347],\n",
       "     [707, 1302],\n",
       "     [700, 1263],\n",
       "     [687, 1231],\n",
       "     [678, 1195],\n",
       "     [662, 1150],\n",
       "     [636, 1128],\n",
       "     [623, 1105],\n",
       "     [613, 1083]],\n",
       "    'difficult': False},\n",
       "   'text': [{'transcription': '약',\n",
       "     'points': [[71, 45],\n",
       "      [45, 138],\n",
       "      [36, 225],\n",
       "      [42, 309],\n",
       "      [81, 435],\n",
       "      [103, 496],\n",
       "      [155, 500],\n",
       "      [200, 390],\n",
       "      [223, 293],\n",
       "      [223, 203],\n",
       "      [200, 138],\n",
       "      [174, 67],\n",
       "      [129, 29]],\n",
       "     'difficult': False}]}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
