{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('train1/source/간판'),\n",
       " PosixPath('val1/source/간판'),\n",
       " PosixPath('train2/source/간판'),\n",
       " PosixPath('val2/source/간판')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "CHECK_LIST_PATH = \"/home/code/dataset/aihub/hangul_real_image_dataset/use.yml\"\n",
    "with open(CHECK_LIST_PATH) as f:\n",
    "    json = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "def f(check_list, path):\n",
    "    check_list = dict(check_list)\n",
    "    path = Path(path)\n",
    "    if isinstance(check_list, dict):\n",
    "        if check_list[\"all\"] == True:\n",
    "            return [path]\n",
    "        elif check_list[\"all\"] == False:\n",
    "            return []\n",
    "        else:\n",
    "            del check_list[\"all\"]\n",
    "            return sum([f(v, path/k) for k, v in check_list.items()], [])\n",
    "\n",
    "    if check_list == True:\n",
    "        return [path]\n",
    "\n",
    "# f(json)\n",
    "\n",
    "f(json, Path(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 1, 2, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([[1, 2, 3], [1, 2, 3]], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x = {\"a\": 1, \"b\":2}\n",
    "for k, v in x.items():\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90| 9\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "90| 9\n",
      "90| 9\n",
      "90| 9\n",
      "89|10\n",
      "90| 9\n",
      "90| 9\n",
      "90| 9\n",
      "89|10\n",
      "90| 9\n",
      "89|10\n",
      "90| 9\n",
      "89|10\n",
      "89|10\n",
      "90| 9\n",
      "90| 9\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "89|10\n",
      "90| 9\n",
      "90| 9\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def check(path):\n",
    "    with open(path) as f:\n",
    "        data = f.readlines()\n",
    "    x = [Path(line.rstrip('\\n').split('\\t')[0]) for line in data]\n",
    "    dir_list= [v.parent.stem for v in x]\n",
    "    return pd.Series(dir_list).value_counts()\n",
    "        \n",
    "train = check(\"/home/dataset/train_label.txt\")\n",
    "val = check(\"/home/dataset/val_label.txt\")\n",
    "test = check(\"/home/dataset/test_label.txt\")\n",
    "\n",
    "\n",
    "for t, v, te in zip(train, val, test):\n",
    "    total = (t+v+te)/100\n",
    "    print(f\"{int(t/total):>2}|{int(v/total):>2}|{int(te/total):>2}\")\n",
    "        \n",
    "        \n",
    "# for t, v in zip(train, val):\n",
    "#     total = (t+v)/100\n",
    "#     print(f\"{int(t/total):>}|{int(v/total):>2}\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.transpose of    가로형간판  창문이용광고물  실내안내판1  가로형간판5  실내간판1  가로형간판1  세로형간판  가로형간판2  가로형간판4  \\\n",
       "0  33613    25714   24488   24117  23628   22521  22382   21997   21804   \n",
       "1   3571     2845    2749    2869   2634    2467   2566    2485    2362   \n",
       "\n",
       "   돌출간판1  ...  사회과학  실내안내판    언어    기타    종교  자연과학    철학    총류    예술    역사  \n",
       "0  21738  ...  4860   4073  3000  2799  2196  2089  2082  1838  1810  1618  \n",
       "1   2499  ...   562    458   323   281   248   233   235   218   189   176  \n",
       "\n",
       "[2 rows x 30 columns]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([train, val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('__main__')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Path(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "가로형간판      3571\n",
       "가로형간판5     2869\n",
       "창문이용광고물    2845\n",
       "실내안내판1     2749\n",
       "실내간판1      2634\n",
       "세로형간판      2566\n",
       "돌출간판1      2499\n",
       "가로형간판2     2485\n",
       "가로형간판1     2467\n",
       "가로형간판4     2362\n",
       "가로형간판3     2323\n",
       "현수막        2235\n",
       "돌출간판2      2215\n",
       "실내간판2      2104\n",
       "지주이용간판     2034\n",
       "실내간판       1327\n",
       "실내안내판2     1098\n",
       "문학          678\n",
       "기술과학        635\n",
       "사회과학        562\n",
       "돌출간판        561\n",
       "실내안내판       458\n",
       "언어          323\n",
       "기타          281\n",
       "종교          248\n",
       "철학          235\n",
       "자연과학        233\n",
       "총류          218\n",
       "예술          189\n",
       "역사          176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: The target file '/home/dataset/AIHUB/temp/VL1' already exist. It's not done to unzip this file. For doint this, delete the target file\n",
      "Note: The target file '/home/dataset/AIHUB/temp/VS1' already exist. It's not done to unzip this file. For doint this, delete the target file\n"
     ]
    }
   ],
   "source": [
    "from config_loader import YamlConfigLoader\n",
    "from aihub import ExternelKoreanImage\n",
    "        \n",
    "        \n",
    "DATASET_ROOT = \"/home/dataset\"\n",
    "CONFIG_PATH = \"/home/dataset/AIHUB/tool/ai_hub_config.yml\"\n",
    "args = YamlConfigLoader.load_config(CONFIG_PATH)\n",
    "dataset = ExternelKoreanImage(args)\n",
    "dataset.unzip() # 기본적으로 다운을 받으면 압축되어 있어 이를 풀어줌\n",
    "dataset.clean_zip() # 압축 풀기 후 데이터 셋 안에 중복된 zip 파일들이 있어 이를 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dataset/AIHUB/temp/VS1/1.간판/가로형간판/간판_가로형간판_018843.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2248567/2995138559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dataset/AIHUB/tool/open_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sample_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dataset/AIHUB/tool/aihub.py\u001b[0m in \u001b[0;36mload_label\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dataset/AIHUB/temp/VS1/1.간판/가로형간판/간판_가로형간판_018843.json'"
     ]
    }
   ],
   "source": [
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "Path(\"/home/dataset/hello/test1.txt\").parent.mkdir(parents=True, exist_ok=True)\n",
    "Path(\"/home/dataset/test1.txt\").rename(\"/home/dataset/hello/test1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dataset/hello/hello/test1.txt' -> '/home/dataset/hello/hello/hello/test1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2248567/1854688777.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/dataset/hello/hello/test1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/dataset/hello/hello/hello/test1.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   1341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1343\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msymlink_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_is_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/dataset/hello/hello/test1.txt' -> '/home/dataset/hello/hello/hello/test1.txt'"
     ]
    }
   ],
   "source": [
    "Path(\"/home/dataset/hello/hello/test1.txt\").replace(\"/home/dataset/hello/hello/hello/test1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/\"\n",
    "\n",
    "\n",
    "def move(origin_path, target_path):\n",
    "    origin_path = Path(origin_path)\n",
    "    target_path = Path(target_path)\n",
    "    target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    origin_path.rename(target_path)\n",
    "\n",
    "\n",
    "move(\"/home/dataset/hello/test1.txt\", \"/home/dataset/hello/hello/test1.txt\")\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": 2}'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.dumps({\"1\":2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1042816/2739929625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "[1, 2, 3]/3\n",
    "map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'PPOCR_STD_Dataset_Loader' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 94\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m    \n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# class PPOCR_STD_Dataset_Converter(Dataset_Converter):\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m#     def __init__(self, dataset_loader):\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m#         self.__dataset_loader = dataset_loader\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m#     def get_y(self, index):\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'PPOCR_STD_Dataset_Loader' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import polygon_utility\n",
    "\n",
    "def make_and_save_recognition_dataset(dataset, save_dir, dir_size=1000, label_file_name = \"label.txt\"):\n",
    "    assert not save_dir.exists(), f\"please remove {save_dir}\"\n",
    "    label_path = save_dir/label_file_name\n",
    "    image_idx = 0\n",
    "\n",
    "    for i in range(len(dataset)):  \n",
    "        image = dataset.get_x(i)[\"image\"]\n",
    "        labels = dataset.get_y(i)\n",
    "        \n",
    "        for label in labels:\n",
    "            polygon =  label[\"polygon\"]\n",
    "            text = label[\"text\"]\n",
    "            \n",
    "            cropped_image = polygon_utility.crop_by_polygon(image, polygon)\n",
    "            image_path = save_dir/f\"{(image_idx//dir_size + 1)}\"/f\"{image_idx+1}.png\"\n",
    "            image_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            cropped_image.save(image_path)\n",
    "            with open(label_path, \"a\") as f:\n",
    "                f.write(f\"{str(image_path)}\\t{text}\\n\")\n",
    "\n",
    "            image_idx += 1\n",
    "\n",
    "dataset = PPOCR_STD_Dataset_Loader(\"E:/workspace/paddleocr/datasets/sangmu_MH_std\")\n",
    "save_dir = Path('./result')\n",
    "make_and_save_recognition_dataset(dataset, save_dir, dir_size=1000, label_file_name = \"Label.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
