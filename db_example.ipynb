{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai_hub_korean_det',\n",
       " 'ai_hub_korean_rec',\n",
       " 'ICDAR2015',\n",
       " 'outsourcing1(exception)_std',\n",
       " 'outsourcing1(exception)_str',\n",
       " 'outsourcing1_std',\n",
       " 'outsourcing1_str',\n",
       " 'sangmu_std_DH',\n",
       " 'sangmu_std_DI',\n",
       " 'sangmu_std_MH',\n",
       " 'sangmu_str_DH',\n",
       " 'sangmu_str_DI',\n",
       " 'sangmu_str_MH',\n",
       " 'test']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "\n",
    "datasetdb = DatasetDB()\n",
    "datasetdb.get_all_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 레이블 셋 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval': ['labelsets/test/eval_label.txt'],\n",
       " 'test': ['labelsets/test/test_label.txt'],\n",
       " 'train': ['labelsets/test/train_label.txt']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "datadb = DatasetDB()\n",
    "labeldb = LabelsetDB()\n",
    "datadb.get_all_id()\n",
    "\n",
    "# labeldb.make(\"test\", [\"test\"], split_ratio=[8, 1, 1], random_seed=100)\n",
    "labeldb.get_config(\"test\", relative_to = \"project\")[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:/workspace/paddleocr/datasets/id/path'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "datadb = DatasetDB()\n",
    "datadb.relative_to(\"id\", \"path\", \"absolute\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('test/hello/world/text.txt')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "x = \"./hello/world/text.txt\"\n",
    "Path(\"./test/\")/x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레이블 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. save label files\n",
      "3. make infer label files\n"
     ]
    }
   ],
   "source": [
    "from database import *\n",
    "datadb = DatasetDB()\n",
    "labeldb = LabelsetDB()\n",
    "datadb.get_all_id()\n",
    "\n",
    "labeldb.make(\"sangmu_std\", [\"sangmu_std_MH\", \"sangmu_std_DI\", \"sangmu_std_DH\"], split_ratio=[8, 1, 1], random_seed=100)\n",
    "labeldb.make(\"sangmu_str\", [\"sangmu_str_MH\", \"sangmu_str_DI\", \"sangmu_str_DH\"], split_ratio=[8, 1, 1], random_seed=100)\n",
    "labeldb.make(\"outsourcing_std2\", [\"outsourcing1_std\", \"outsourcing1(exception)_std\"], [8, 1, 1], random_seed=100)\n",
    "labeldb.make(\"outsourcing_str\", [\"outsourcing1_str\", \"outsourcing1(exception)_str\"], [8, 1, 1], random_seed=100)\n",
    "\n",
    "labeldb.make(\"sangmu_and_outsourcing_std\", [\"outsourcing1_std\", \"outsourcing1(exception)_std\"], [8, 2, 0], individual_split_ratio={\n",
    "    \"sangmu_std_MH\":[0, 0, 1],\n",
    "    \"sangmu_std_DI\":[0, 0, 1],\n",
    "    \"sangmu_std_DH\":[0, 0, 1]\n",
    "    }, random_seed=100)\n",
    "\n",
    "labeldb.make(\"sangmu_and_outsourcing_str\", [\"outsourcing1_str\", \"outsourcing1(exception)_str\"], [8, 2, 0], individual_split_ratio={\n",
    "    \"sangmu_str_MH\":[0, 0, 1],\n",
    "    \"sangmu_str_DI\":[0, 0, 1],\n",
    "    \"sangmu_str_DH\":[0, 0, 1]\n",
    "    }, random_seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k_fold 레이블 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from database import *\n",
    "# labeldb = LabelsetDB()\n",
    "# labeldb.make_k_fold([\"test2\"], \"test_k_fold\", k=5)\n",
    "# labeldb.get_config(\"test_k_fold_5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inference_model': 'E:/workspace/paddleocr/models/en_PP-OCRv3_det/inference_model/Student/inference.pdmodel',\n",
       " 'inference_model_dir': 'E:/workspace/paddleocr/models/en_PP-OCRv3_det/inference_model/Student',\n",
       " 'inference_model_weight': 'E:/workspace/paddleocr/models/en_PP-OCRv3_det/inference_model/Student/inference.pdiparams',\n",
       " 'pretrained_model_dir': 'E:/workspace/paddleocr/models/en_PP-OCRv3_det/pretrained_model',\n",
       " 'pretrained_model_weight': 'E:/workspace/paddleocr/models/en_PP-OCRv3_det/pretrained_model/pretrained.pdparams',\n",
       " 'train_config': 'E:/workspace/paddleocr/models/en_PP-OCRv3_det/pretrained_model/config.yml'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "modeldb = ModelDB()\n",
    "import os\n",
    "# modeldb.get_config(\"en_PP-OCRv3_det\")\n",
    "modeldb.get_all_id()\n",
    "modeldb.get_config(\"en_PP-OCRv3_det\", relative_to=\"absolute\")\n",
    "# for id in modeldb.get_all_id():\n",
    "#     print(id)\n",
    "#     modeldb.make_inference_model(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Work Make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "the work 'rec_PPOCR_sangmu' already exist!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m workdb \u001b[38;5;241m=\u001b[39m WorkDB()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# workdb.make(\"det_PPOCR_sangmu\", [\"sangmu_std\"], \"ml_PP-OCRv3_det\")\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# workdb.make(\"det_PPOCR_oursourcing2\", [\"outsourcing_std\"], \"ml_PP-OCRv3_det\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# workdb.make(\"det_PPOCR_sangmu_and_oursourcing\", [\"sangmu_and_outsourcing_std\"], \"ml_PP-OCRv3_det\")\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mworkdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrec_PPOCR_sangmu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msangmu_str\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkorean_PP-OCRv3_rec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m workdb\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec_PPOCR_oursourcing2\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutsourcing_str\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkorean_PP-OCRv3_rec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m workdb\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrec_PPOCR_sangmu_and_oursourcing\u001b[39m\u001b[38;5;124m\"\u001b[39m, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msangmu_and_outsourcing_str\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkorean_PP-OCRv3_rec\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\workspace\\paddleocr\\code\\database\\work_db.py:27\u001b[0m, in \u001b[0;36mWorkDB.make\u001b[1;34m(self, name, labelsets, model)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, labelsets, model):\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_id(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe work \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m labelset \u001b[38;5;129;01min\u001b[39;00m labelsets:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m labelset \u001b[38;5;129;01min\u001b[39;00m LabelsetDB()\u001b[38;5;241m.\u001b[39mget_all_id(), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe labelset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabelset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: the work 'rec_PPOCR_sangmu' already exist!"
     ]
    }
   ],
   "source": [
    "from database import *\n",
    "workdb = WorkDB()\n",
    "# workdb.make(\"det_PPOCR_sangmu\", [\"sangmu_std\"], \"ml_PP-OCRv3_det\")\n",
    "# workdb.make(\"det_PPOCR_oursourcing2\", [\"outsourcing_std\"], \"ml_PP-OCRv3_det\")\n",
    "# workdb.make(\"det_PPOCR_sangmu_and_oursourcing\", [\"sangmu_and_outsourcing_std\"], \"ml_PP-OCRv3_det\")\n",
    "\n",
    "workdb.make(\"rec_PPOCR_sangmu\", [\"sangmu_str\"], \"korean_PP-OCRv3_rec\")\n",
    "workdb.make(\"rec_PPOCR_oursourcing2\", [\"outsourcing_str\"], \"korean_PP-OCRv3_rec\")\n",
    "workdb.make(\"rec_PPOCR_sangmu_and_oursourcing\", [\"sangmu_and_outsourcing_str\"], \"korean_PP-OCRv3_rec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "workdb = WorkDB()\n",
    "workdb.infer(\"det_PPOCR_sangmu\", \"best\", \"test\")\n",
    "workdb.infer(\"det_PPOCR_oursourcing\", \"best\", \"test\")\n",
    "workdb.infer(\"det_PPOCR_sangmu_and_oursourcing\", \"latest\", \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Work Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python code/PaddleOCR/tools/train.py -c works/rec_PPOCR_sangmu/train_config.yml -o Global.checkpoints=models/korean_PP-OCRv3_rec/pretrained_model/pretrained Global.epoch_num=10 Global.save_model_dir=works/rec_PPOCR_sangmu/trained_model Train.dataset.data_dir=./datasets Train.dataset.label_file_list=['labelsets/sangmu_str/train_label.txt'] Eval.dataset.data_dir=./datasets Eval.dataset.label_file_list=['labelsets/sangmu_str/eval_label.txt']\n",
      "python code/PaddleOCR/tools/train.py -c works/rec_PPOCR_oursourcing2/train_config.yml -o Global.checkpoints=models/korean_PP-OCRv3_rec/pretrained_model/pretrained Global.epoch_num=10 Global.save_model_dir=works/rec_PPOCR_oursourcing2/trained_model Train.dataset.data_dir=./datasets Train.dataset.label_file_list=['labelsets/outsourcing_str/train_label.txt'] Eval.dataset.data_dir=./datasets Eval.dataset.label_file_list=['labelsets/outsourcing_str/eval_label.txt']\n",
      "python code/PaddleOCR/tools/train.py -c works/rec_PPOCR_sangmu_and_oursourcing/train_config.yml -o Global.checkpoints=models/korean_PP-OCRv3_rec/pretrained_model/pretrained Global.epoch_num=10 Global.save_model_dir=works/rec_PPOCR_sangmu_and_oursourcing/trained_model Train.dataset.data_dir=./datasets Train.dataset.label_file_list=['labelsets/sangmu_and_outsourcing_str/train_label.txt'] Eval.dataset.data_dir=./datasets Eval.dataset.label_file_list=['labelsets/sangmu_and_outsourcing_str/eval_label.txt']\n"
     ]
    }
   ],
   "source": [
    "from database import *\n",
    "workdb = WorkDB()\n",
    "modeldb = ModelDB()\n",
    "labelsetdb = LabelsetDB()\n",
    "\n",
    "\n",
    "workdb.train(\"rec_PPOCR_sangmu\", \"latest\", 10, relative_to=\"project\")\n",
    "workdb.train(\"rec_PPOCR_oursourcing\", \"latest\", 10, relative_to=\"project\")\n",
    "workdb.train(\"rec_PPOCR_sangmu_and_oursourcing\", \"latest\", 10, relative_to=\"project\")\n",
    "\n",
    "workdb.train(\"det_PPOCR_sangmu\", \"best\", 10, relative_to=\"absolute\") \n",
    "workdb.train(\"det_PPOCR_oursourcing\", \"best\", 10, relative_to=\"project\") \n",
    "workdb.train(\"det_PPOCR_sangmu_and_oursourcing\", \"best\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python code/PaddleOCR/tools/eval.py -c works/det_PPOCR_sangmu_old/train_config.yml -o Global.work_id=det_PPOCR_sangmu_old Global.version=latest Global.eval_dataset=test Global.checkpoints=works/det_PPOCR_sangmu_old/trained_model/latest.pdparams Global.save_model_dir=works/det_PPOCR_sangmu_old/trained_model Eval.dataset.data_dir=./datasets Eval.dataset.label_file_list=['labelsets/sangmu_std/test_label.txt']\n"
     ]
    }
   ],
   "source": [
    "from database import *\n",
    "workdb = WorkDB()\n",
    "workdb.eval(\"det_PPOCR_sangmu_old\", version=\"latest\", dataset=\"test\")\n",
    "# workdb.eval(\"det_PPOCR_oursourcing\", \"best\", 10, relative_to=\"project\") \n",
    "# workdb.eval(\"det_PPOCR_sangmu_and_oursourcing\", \"best\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>step</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.399777</td>\n",
       "      <td>0.656307</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  version  step  acc  loss  precision    recall dataset\n",
       "0  latest   NaN  NaN   NaN   0.666667  1.000000     NaN\n",
       "0  latest   NaN  NaN   NaN   0.666667  1.000000     NaN\n",
       "0  latest   NaN  NaN   NaN   0.399777  0.656307    test"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "workdb = WorkDB()\n",
    "workdb.get_report_df(\"det_PPOCR_sangmu_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "import project\n",
    "from pathlib import Path\n",
    "# config = \"configs\\det\\det_mv3_db.yml\"\n",
    "# labelsets = [\"test\", \"test_k_fold_5_1\"]\n",
    "# model = \"MobileNetV3_large_x0_5\"\n",
    "# name = \"test\"\n",
    "# WorkDB().make(name, labelsets, model, config)\n",
    "\n",
    "WorkDB().train(\"test\", 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from database import *\n",
    "from pathlib import Path\n",
    "\n",
    "def full_infer(image_dir, det_model_dir, rec_model_dir, save_dir):\n",
    "    code = 'code/PaddleOCR/tools/infer/predict_system.py'\n",
    "    det_algorithm=\"DB\"\n",
    "\n",
    "    # rec_model_dir = \"E:/workspace/paddleocr/outputs/rec___korean_PP-OCRv3_rec___rec_08_02_90_random_k_fold_5_1___default_config___finetune/trained_model/inference_model\"\n",
    "    rec_char_dict_path = \"E:/workspace/paddleocr/code/PaddleOCR/ppocr/utils/dict/korean_dict.txt\"\n",
    "    vis_font_path = \"C:\\Windows\\Fonts\\malgun.ttf\"\n",
    "\n",
    "    command = f\"\"\"python {code} --image_dir={image_dir} \\\n",
    "    --det_model_dir={det_model_dir} \\\n",
    "    --det_algorithm={det_algorithm} \\\n",
    "    --rec_model_dir={rec_model_dir} \\\n",
    "    --rec_image_shape=\"3, 32, 100\" \\\n",
    "    --rec_char_dict_path={rec_char_dict_path} \\\n",
    "    --vis_font_path={vis_font_path} \\\n",
    "    --draw_img_save_dir={save_dir} \\\n",
    "    --drop_score=0.3 \\\n",
    "    --det_db_box_thresh=0.4\"\"\"\n",
    "    \n",
    "    path = Path(project.PROJECT_ROOT)/\"inference/run.sh\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"a\") as f:\n",
    "        f.write(command+\"\\n\")\n",
    "    \n",
    "modeldb = ModelDB()\n",
    "workdb = WorkDB()\n",
    "\n",
    "# det_model_dir = modeldb.get_config(\"MobileNetV3_large_x0_5\")[\"inference_model_dir\"] \n",
    "# rec_model_dir = modeldb.get_config(\"korean_PP-OCRv3_rec\")[\"inference_model_dir\"]\n",
    "# save_dir = f\"{project.PROJECT_ROOT}/inference/Mobile_PaddleOCR_pretrained\"\n",
    "# full_infer(det_model_dir, rec_model_dir, save_dir)\n",
    "\n",
    "# image_dir = \"./origin_datasets/sangmu_real_image_det(cropped)\"\n",
    "# det_model_dir = modeldb.get_config(\"ml_PP-OCRv3_det\")[\"inference_model_dir\"]\n",
    "# rec_model_dir = modeldb.get_config(\"korean_PP-OCRv3_rec\")[\"inference_model_dir\"]\n",
    "# save_dir = f\"{project.PROJECT_ROOT}/inference/PaddleOCR_PaddleOCR_pretrained_sangmu\"\n",
    "# full_infer(image_dir, det_model_dir, rec_model_dir, save_dir)\n",
    "\n",
    "image_dir = \"./origin_datasets/sangmu_real_image_det(cropped)\"\n",
    "det_model_dir = workdb.get_config(\"det___ml_PP-OCRv3_det___ai_hub_det_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "rec_model_dir = workdb.get_config(\"rec___korean_PP-OCRv3_rec___rec_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "save_dir = f\"{project.PROJECT_ROOT}/inference/PPOCR_PPOCR_tuned_sangmu\"\n",
    "full_infer(image_dir, det_model_dir, rec_model_dir, save_dir)\n",
    "\n",
    "image_dir = \"./datasets/ai_hub_korean_det_partial_test/images\"\n",
    "det_model_dir = workdb.get_config(\"det___ml_PP-OCRv3_det___ai_hub_det_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "rec_model_dir = workdb.get_config(\"rec___korean_PP-OCRv3_rec___rec_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "save_dir = f\"{project.PROJECT_ROOT}/inference/PPOCR_PPOCR_tuned_aihub\"\n",
    "full_infer(image_dir, det_model_dir, rec_model_dir, save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"./datasets/ai_hub_korean_image_det/train2/source/간판/돌출간판/돌출간판1/간판_돌출간판_001449.jpg\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80242 25621 55803\n"
     ]
    }
   ],
   "source": [
    "with open(\"E:/workspace/paddleocr/datasets/ai_hub_korean_det/label2.txt\") as f:\n",
    "    lines = [line.rstrip(\"\\n\") for line in f.readlines()]\n",
    "\n",
    "a, b, c = 0, 0, 0\n",
    "for line in lines:\n",
    "    if \"가로형간판\" in line:\n",
    "        a+= 1\n",
    "    elif \"세로형간판\" in line:\n",
    "        b+= 1\n",
    "    elif \"돌출간판\" in line:\n",
    "        c+= 1\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:/workspace/paddleocr/datasets/ai_hub_korean_det/label3.txt\", encoding=\"cp949\") as f:\n",
    "    with open(\"E:/workspace/paddleocr/datasets/ai_hub_korean_det/label2.txt\", \"w\", encoding=\"utf-8\") as f2:\n",
    "        for line in f.readlines():\n",
    "            f2.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Checked Dir List*******\n",
      "datasets\\ai_hub_korean_det\\train1\\source\\간판\\세로형간판\n",
      "datasets\\ai_hub_korean_det\\val1\\source\\간판\\세로형간판\n",
      "datasets\\ai_hub_korean_det\\train2\\source\\간판\\가로형간판\\가로형간판1\n",
      "datasets\\ai_hub_korean_det\\train2\\source\\간판\\돌출간판\\돌출간판1\n",
      "datasets\\ai_hub_korean_det\\train2\\source\\간판\\세로형간판\n",
      "datasets\\ai_hub_korean_det\\val2\\source\\간판\\세로형간판\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "from dataset.aihub.hangul_real_image_dataset import *\n",
    "dataset = HangulRealImageDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HangulRealImage_BoxDetectionDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bbox': [[762, 306], [849, 306], [849, 518], [762, 518]], 'label': '소망'},\n",
       " {'bbox': [[754, 547], [837, 547], [837, 900], [754, 900]], 'label': '미용실'},\n",
       " {'bbox': [[730, 1053], [845, 1053], [845, 1147], [730, 1147]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[871, 1078], [1047, 1078], [1047, 1139], [871, 1139]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[1177, 732], [1479, 732], [1479, 794], [1177, 794]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[1429, 707], [1502, 707], [1502, 748], [1429, 748]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[1342, 1075], [1428, 1075], [1428, 1160], [1342, 1160]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[184, 345], [361, 345], [361, 611], [184, 611]], 'label': 'xxx'},\n",
       " {'bbox': [[121, 291], [184, 291], [184, 342], [121, 342]], 'label': 'xxx'},\n",
       " {'bbox': [[365, 194], [460, 194], [460, 252], [365, 252]], 'label': 'xxx'},\n",
       " {'bbox': [[391, 536], [443, 536], [443, 587], [391, 587]], 'label': 'xxx'},\n",
       " {'bbox': [[355, 610], [517, 610], [517, 684], [355, 684]], 'label': 'xxx'},\n",
       " {'bbox': [[172, 748], [240, 748], [240, 802], [172, 802]], 'label': 'xxx'},\n",
       " {'bbox': [[0, 168], [736, 168], [736, 1154], [0, 1154]], 'label': 'xxx'},\n",
       " {'bbox': [[998, 1], [1600, 1], [1600, 1092], [998, 1092]], 'label': 'xxx'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "dataset.show_xy(x, y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  step  acc  loss  precision  recall\n",
       "0    1.0   2.0  3.0   4.0        5.0     1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({\"epoch\":[], \"step\":[], \"acc\":[], \"loss\":[], \"precision\":[], \"recall\":[]})\n",
    "\n",
    "df = df._append({\"epoch\":1, \"step\":2, \"acc\":3, \"loss\":4, \"precision\":5, \"recall\":1}, ignore_index=True)\n",
    "df.to_csv(\"test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  step  acc  loss  precision  recall\n",
       "0    1.0   2.0  3.0   4.0        5.0     1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'det_MobileNet_sangmu',\n",
       " 'labelsets': ['sangmu'],\n",
       " 'model': 'MobileNetV3_large_x0_5',\n",
       " 'pretrained': True,\n",
       " 'train_config': './works/det_MobileNet_sangmu/train_config.yml',\n",
       " 'result_path': './works/det_MobileNet_sangmu/result.csv'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "\n",
    "WorkDB().get_all_id()\n",
    "WorkDB().get_config(\"det_MobileNet_sangmu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "\n",
    "WorkDB().get_all_id()\n",
    "# WorkDB().infer_det(\"det_MobileNet_sangmu\")\n",
    "# WorkDB().get_best_model_weight(\"det_MobileNet_sangmu\")\n",
    "# WorkDB().infer_det(\"det_MobileNet_sangmu\", \"test\", \"best\")\n",
    "WorkDB().infer_det(\"det_PPOCR_sangmu\", \"best\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:/5.SCI Lab/1.과제 & 연구/[2023] 불법옥외간판(외주)/데이터셋/레이블링 결과(최종)_0126/그외 간판\"\n",
    "\n",
    "wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 140, 200]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_dir': './datasets',\n",
       " 'datasets': ['sangmu_std_MH', 'sangmu_std_DI', 'sangmu_std_DH'],\n",
       " 'infer': {'eval': ['eval_infer.txt'],\n",
       "  'test': ['test_infer.txt'],\n",
       "  'train': ['train_infer.txt']},\n",
       " 'label': {'eval': ['eval_label.txt'],\n",
       "  'test': ['test_label.txt'],\n",
       "  'train': ['train_label.txt']},\n",
       " 'seed': 100,\n",
       " 'split': {'sangmu_std_DH': [8, 1, 1],\n",
       "  'sangmu_std_DI': [8, 1, 1],\n",
       "  'sangmu_std_MH': [8, 1, 1]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"E:/workspace/paddleocr/labelsets/test1/config.yml\") as f:\n",
    "    x = yaml.load(f, Loader=yaml.FullLoader)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 2: 20}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1:1, 2:2}\n",
    "y = {1:10, 2:20}\n",
    "\n",
    "x.update(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 436 (char 435)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxxx\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [[870, 422], [865, 430], [867, 441], [879, 435], [894, 425], [903, 407], [905, 377], [891, 356], [854, 342], [806, 345], [771, 358], [759, 384], [754, 404], [769, 428], [813, 446], [839, 449], [853, 443], [855, 433], [831, 435], [806, 430], [786, 420], [776, 410], [770, 392], [777, 373], [792, 365], [813, 355], [837, 353], [862, 358], [877, 371], [885, 386], [888, 406], [876, 415]], \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficult\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: alse}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSM\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [[806, 369], [862, 375], [864, 399], [809, 401], [801, 388]], \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficult\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: false}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muc724\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muc2b9\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mubbf8\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mud559\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muc6d0\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [[963, 387], [938, 388], [934, 412], [947, 434], [966, 470], [1050, 475], [1155, 464], [1335, 479], [1467, 477], [1627, 480], [1627, 364], [1518, 361], [1433, 354], [1388, 356], [1236, 357], [1151, 349], [992, 342], [966, 346]], \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficult\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: false}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muad50\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muc721\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124muc0c1\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mub2f4\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [[1044, 516], [1140, 516], [1140, 548], [1044, 548]], \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficult\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: false}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranscription\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m971-3338\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoints\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: [[1163, 512], [1403, 512], [1403, 558], [1163, 558]], \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifficult\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: false}]\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      4\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\paddle_env\\lib\\json\\__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\paddle_env\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\admin\\anaconda3\\envs\\paddle_env\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 436 (char 435)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'set' and 'set'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'set' and 'set'"
     ]
    }
   ],
   "source": [
    "sum([{1}, {1}, {1}], set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "\n",
    "# 운영체제 이름\n",
    "os_name = platform.system()\n",
    "print(os_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddlelabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
