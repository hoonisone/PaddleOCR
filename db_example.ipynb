{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai_hub_korean_det', 'ai_hub_korean_rec', 'ICDAR2015', 'sangmu_MH_std', 'test1', 'test2']\n",
      "\n",
      "ai_hub_korean_det\n",
      "{'task': ['STD'], 'labelfiles': ['label1.txt'], 'options': [], 'id': 'ai_hub_korean_det'}\n"
     ]
    }
   ],
   "source": [
    "from database import *\n",
    "\n",
    "mdb = DatasetDB()\n",
    "print(mdb.get_all_id())\n",
    "print()\n",
    "id = mdb.get_all_id()[0]\n",
    "print(id)\n",
    "print(mdb.get_config(id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 레이블 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images/1.png\t[{\"transcription\": \"IBK WM 센터 광주\", \"points\": [[535, 27], [2683, 27], [2683, 343], [535, 343]], \"difficult\": false}, {\"transcription\": \"IBK 기업은행\", \"points\": [[2777, 63], [3343, 63], [3343, 163], [2777, 163]], \"difficult\": false}, {\"transcription\": \"IBK 투자증권\", \"points\": [[2797, 171], [3362, 171], [3362, 274], [2797, 274]], \"difficult\": false}]\n",
      "images/1.png\t[{\"transcription\": \"NH농협은행\", \"points\": [[226, 67], [808, 67], [808, 172], [226, 172]], \"difficult\": false}, {\"transcription\": \"365 Auto Bank\", \"points\": [[1010, 132], [2332, 132], [2332, 376], [1010, 376]], \"difficult\": false}]\n",
      "images/1.png\t[{\"transcription\": \"TIMESTOWER\", \"points\": [[16, 6], [153, 9], [147, 39], [475, 52], [509, 13], [636, 18], [642, 41], [1016, 59], [1051, 67], [1071, 179], [25, 159], [12, 40]], \"difficult\": false}]\n",
      "2. save label files\n",
      "3. make infer label files\n",
      "E:\\workspace\\paddleocr\\datasets\\sangmu_str_MH\\1\\1.png\tIBK WM 센터 광주\n",
      "E:\\workspace\\paddleocr\\datasets\\sangmu_str_DI\\1\\1.png\tNH농협은행\n",
      "E:\\workspace\\paddleocr\\datasets\\sangmu_str_DH\\1\\1.png\tTIMESTOWER\n",
      "2. save label files\n",
      "3. make infer label files\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1_std\\1\\1.png\t[{\"transcription\": \"\\ub300\\ud55c\\uc608\\uc218\\uad50\", \"points\": [[1136, 1278], [1582, 1278], [1582, 1372], [1136, 1372]], \"difficult\": false}, {\"transcription\": \"\\uc7a5\\ub85c\\ud68c\", \"points\": [[1139, 1372], [1586, 1372], [1586, 1455], [1139, 1455]], \"difficult\": false}, {\"transcription\": \"\\uc0ac\\ub791\\uc758\\uad50\\ud68c\", \"points\": [[1629, 1288], [2522, 1288], [2522, 1452], [1629, 1452]], \"difficult\": false}]\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1(exception)_std\\1\\1.png\t[{\"transcription\": \"\\uc591\\uc120\\ube44\", \"points\": [[761, 1228], [827, 1199], [1002, 1224], [1005, 1319], [823, 1350], [751, 1288]], \"difficult\": false}, {\"transcription\": \"\\uc591\\uac08\\ube44\", \"points\": [[1020, 1271], [1063, 1267], [1079, 1279], [1081, 1309], [1028, 1310]], \"difficult\": false}, {\"transcription\": \"\\ucca8\\ub2e8\\uc9c1\\uc601\\uc810\", \"points\": [[1288, 1264], [1410, 1264], [1411, 1295], [1281, 1297]], \"difficult\": false}, {\"transcription\": \"062.974.1804\", \"points\": [[1228, 1301], [1228, 1334], [1412, 1332], [1408, 1297]], \"difficult\": false}]\n",
      "2. save label files\n",
      "3. make infer label files\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1_str\\1\\1.png\t대한예수교\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1(exception)_str\\1\\1.png\t양선비\n",
      "2. save label files\n",
      "3. make infer label files\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1_std\\1\\1.png\t[{\"transcription\": \"\\ub300\\ud55c\\uc608\\uc218\\uad50\", \"points\": [[1136, 1278], [1582, 1278], [1582, 1372], [1136, 1372]], \"difficult\": false}, {\"transcription\": \"\\uc7a5\\ub85c\\ud68c\", \"points\": [[1139, 1372], [1586, 1372], [1586, 1455], [1139, 1455]], \"difficult\": false}, {\"transcription\": \"\\uc0ac\\ub791\\uc758\\uad50\\ud68c\", \"points\": [[1629, 1288], [2522, 1288], [2522, 1452], [1629, 1452]], \"difficult\": false}]\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1(exception)_std\\1\\1.png\t[{\"transcription\": \"\\uc591\\uc120\\ube44\", \"points\": [[761, 1228], [827, 1199], [1002, 1224], [1005, 1319], [823, 1350], [751, 1288]], \"difficult\": false}, {\"transcription\": \"\\uc591\\uac08\\ube44\", \"points\": [[1020, 1271], [1063, 1267], [1079, 1279], [1081, 1309], [1028, 1310]], \"difficult\": false}, {\"transcription\": \"\\ucca8\\ub2e8\\uc9c1\\uc601\\uc810\", \"points\": [[1288, 1264], [1410, 1264], [1411, 1295], [1281, 1297]], \"difficult\": false}, {\"transcription\": \"062.974.1804\", \"points\": [[1228, 1301], [1228, 1334], [1412, 1332], [1408, 1297]], \"difficult\": false}]\n",
      "2. save label files\n",
      "3. make infer label files\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1_str\\1\\1.png\t대한예수교\n",
      "E:\\workspace\\paddleocr\\origin_datasets\\external_service1(exception)_str\\1\\1.png\t양선비\n",
      "2. save label files\n",
      "3. make infer label files\n"
     ]
    }
   ],
   "source": [
    "from database import *\n",
    "datadb = DatasetDB()\n",
    "labeldb = LabelsetDB()\n",
    "datadb.get_all_id()\n",
    "\n",
    "labeldb.make(\"sangmu_std\", [\"sangmu_std_MH\", \"sangmu_std_DI\", \"sangmu_std_DH\"], split_ratio=[8, 1, 1], random_seed=100)\n",
    "labeldb.make(\"sangmu_str\", [\"sangmu_str_MH\", \"sangmu_str_DI\", \"sangmu_str_DH\"], split_ratio=[8, 1, 1], random_seed=100)\n",
    "labeldb.make(\"outsourcing_std\", [\"external_service1_std\", \"external_service1(exception)_std\"], [8, 1, 1], random_seed=100)\n",
    "labeldb.make(\"outsourcing_str\", [\"external_service1_str\", \"external_service1(exception)_str\"], [8, 1, 1], random_seed=100)\n",
    "\n",
    "labeldb.make(\"sangmu_and_outsourcing_std\", [\"external_service1_std\", \"external_service1(exception)_std\"], [8, 2, 0], individual_split_ratio={\n",
    "    \"sangmu_std_MH\":[0, 0, 1],\n",
    "    \"sangmu_std_DI\":[0, 0, 1],\n",
    "    \"sangmu_std_DH\":[0, 0, 1]\n",
    "    }, random_seed=100)\n",
    "\n",
    "labeldb.make(\"sangmu_and_outsourcing_str\", [\"external_service1_str\", \"external_service1(exception)_str\"], [8, 2, 0], individual_split_ratio={\n",
    "    \"sangmu_str_MH\":[0, 0, 1],\n",
    "    \"sangmu_str_DI\":[0, 0, 1],\n",
    "    \"sangmu_str_DH\":[0, 0, 1]\n",
    "    }, random_seed=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k_fold 레이블 셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from database import *\n",
    "# labeldb = LabelsetDB()\n",
    "# labeldb.make_k_fold([\"test2\"], \"test_k_fold\", k=5)\n",
    "# labeldb.get_config(\"test_k_fold_5_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'MobileNetV3_large_x0_5',\n",
       " 'inference_model': './models/MobileNetV3_large_x0_5/inference_model/inference.pdmodel',\n",
       " 'inference_model_dir': './models/MobileNetV3_large_x0_5/inference_model',\n",
       " 'inference_model_weight': './models/MobileNetV3_large_x0_5/inference_model/inference.pdiparams',\n",
       " 'pretrained_model_dir': './models/MobileNetV3_large_x0_5/pretrained_model',\n",
       " 'pretrained_model_weight': './models/MobileNetV3_large_x0_5/pretrained_model/pretrained.pdparams',\n",
       " 'train_config': './models/MobileNetV3_large_x0_5/pretrained_model/config.yml'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "modeldb = ModelDB()\n",
    "import os\n",
    "# modeldb.get_config(\"en_PP-OCRv3_det\")\n",
    "modeldb.get_all_id()\n",
    "modeldb.get_config(\"MobileNetV3_large_x0_5\")\n",
    "# for id in modeldb.get_all_id():\n",
    "#     print(id)\n",
    "#     modeldb.make_inference_model(id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "workdb = WorkDB()\n",
    "modeldb = ModelDB()\n",
    "labelsetdb = LabelsetDB()\n",
    "modeldb.get_all_id()\n",
    "workdb.make(\"det_PPOCR_sangmu\", [\"sangmu_std\"], \"ml_PP-OCRv3_det\")\n",
    "workdb.make(\"det_PPOCR_oursourcing\", [\"outsourcing_std\"], \"ml_PP-OCRv3_det\")\n",
    "workdb.make(\"det_PPOCR_sangmu_and_oursourcing\", [\"sangmu_and_outsourcing_std\"], \"ml_PP-OCRv3_det\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdb.train(\"det_PPOCR_sangmu\", 10) \n",
    "workdb.train(\"det_PPOCR_oursourcing\", 10) \n",
    "workdb.train(\"det_PPOCR_sangmu_and_oursourcing\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "import project\n",
    "from pathlib import Path\n",
    "# config = \"configs\\det\\det_mv3_db.yml\"\n",
    "# labelsets = [\"test\", \"test_k_fold_5_1\"]\n",
    "# model = \"MobileNetV3_large_x0_5\"\n",
    "# name = \"test\"\n",
    "# WorkDB().make(name, labelsets, model, config)\n",
    "\n",
    "WorkDB().train(\"test\", 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from database import *\n",
    "from pathlib import Path\n",
    "\n",
    "def full_infer(image_dir, det_model_dir, rec_model_dir, save_dir):\n",
    "    code = 'code/PaddleOCR/tools/infer/predict_system.py'\n",
    "    det_algorithm=\"DB\"\n",
    "\n",
    "    # rec_model_dir = \"E:/workspace/paddleocr/outputs/rec___korean_PP-OCRv3_rec___rec_08_02_90_random_k_fold_5_1___default_config___finetune/trained_model/inference_model\"\n",
    "    rec_char_dict_path = \"E:/workspace/paddleocr/code/PaddleOCR/ppocr/utils/dict/korean_dict.txt\"\n",
    "    vis_font_path = \"C:\\Windows\\Fonts\\malgun.ttf\"\n",
    "\n",
    "    command = f\"\"\"python {code} --image_dir={image_dir} \\\n",
    "    --det_model_dir={det_model_dir} \\\n",
    "    --det_algorithm={det_algorithm} \\\n",
    "    --rec_model_dir={rec_model_dir} \\\n",
    "    --rec_image_shape=\"3, 32, 100\" \\\n",
    "    --rec_char_dict_path={rec_char_dict_path} \\\n",
    "    --vis_font_path={vis_font_path} \\\n",
    "    --draw_img_save_dir={save_dir} \\\n",
    "    --drop_score=0.3 \\\n",
    "    --det_db_box_thresh=0.4\"\"\"\n",
    "    \n",
    "    path = Path(project.PROJECT_ROOT)/\"inference/run.sh\"\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, \"a\") as f:\n",
    "        f.write(command+\"\\n\")\n",
    "    \n",
    "modeldb = ModelDB()\n",
    "workdb = WorkDB()\n",
    "\n",
    "# det_model_dir = modeldb.get_config(\"MobileNetV3_large_x0_5\")[\"inference_model_dir\"] \n",
    "# rec_model_dir = modeldb.get_config(\"korean_PP-OCRv3_rec\")[\"inference_model_dir\"]\n",
    "# save_dir = f\"{project.PROJECT_ROOT}/inference/Mobile_PaddleOCR_pretrained\"\n",
    "# full_infer(det_model_dir, rec_model_dir, save_dir)\n",
    "\n",
    "# image_dir = \"./origin_datasets/sangmu_real_image_det(cropped)\"\n",
    "# det_model_dir = modeldb.get_config(\"ml_PP-OCRv3_det\")[\"inference_model_dir\"]\n",
    "# rec_model_dir = modeldb.get_config(\"korean_PP-OCRv3_rec\")[\"inference_model_dir\"]\n",
    "# save_dir = f\"{project.PROJECT_ROOT}/inference/PaddleOCR_PaddleOCR_pretrained_sangmu\"\n",
    "# full_infer(image_dir, det_model_dir, rec_model_dir, save_dir)\n",
    "\n",
    "image_dir = \"./origin_datasets/sangmu_real_image_det(cropped)\"\n",
    "det_model_dir = workdb.get_config(\"det___ml_PP-OCRv3_det___ai_hub_det_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "rec_model_dir = workdb.get_config(\"rec___korean_PP-OCRv3_rec___rec_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "save_dir = f\"{project.PROJECT_ROOT}/inference/PPOCR_PPOCR_tuned_sangmu\"\n",
    "full_infer(image_dir, det_model_dir, rec_model_dir, save_dir)\n",
    "\n",
    "image_dir = \"./datasets/ai_hub_korean_det_partial_test/images\"\n",
    "det_model_dir = workdb.get_config(\"det___ml_PP-OCRv3_det___ai_hub_det_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "rec_model_dir = workdb.get_config(\"rec___korean_PP-OCRv3_rec___rec_08_02_90_random_k_fold_5_1___default_config___finetune\")[\"inference_model_dir\"]\n",
    "save_dir = f\"{project.PROJECT_ROOT}/inference/PPOCR_PPOCR_tuned_aihub\"\n",
    "full_infer(image_dir, det_model_dir, rec_model_dir, save_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"./datasets/ai_hub_korean_image_det/train2/source/간판/돌출간판/돌출간판1/간판_돌출간판_001449.jpg\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80242 25621 55803\n"
     ]
    }
   ],
   "source": [
    "with open(\"E:/workspace/paddleocr/datasets/ai_hub_korean_det/label2.txt\") as f:\n",
    "    lines = [line.rstrip(\"\\n\") for line in f.readlines()]\n",
    "\n",
    "a, b, c = 0, 0, 0\n",
    "for line in lines:\n",
    "    if \"가로형간판\" in line:\n",
    "        a+= 1\n",
    "    elif \"세로형간판\" in line:\n",
    "        b+= 1\n",
    "    elif \"돌출간판\" in line:\n",
    "        c+= 1\n",
    "print(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"E:/workspace/paddleocr/datasets/ai_hub_korean_det/label3.txt\", encoding=\"cp949\") as f:\n",
    "    with open(\"E:/workspace/paddleocr/datasets/ai_hub_korean_det/label2.txt\", \"w\", encoding=\"utf-8\") as f2:\n",
    "        for line in f.readlines():\n",
    "            f2.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Checked Dir List*******\n",
      "datasets\\ai_hub_korean_det\\train1\\source\\간판\\세로형간판\n",
      "datasets\\ai_hub_korean_det\\val1\\source\\간판\\세로형간판\n",
      "datasets\\ai_hub_korean_det\\train2\\source\\간판\\가로형간판\\가로형간판1\n",
      "datasets\\ai_hub_korean_det\\train2\\source\\간판\\돌출간판\\돌출간판1\n",
      "datasets\\ai_hub_korean_det\\train2\\source\\간판\\세로형간판\n",
      "datasets\\ai_hub_korean_det\\val2\\source\\간판\\세로형간판\n",
      "******************************\n"
     ]
    }
   ],
   "source": [
    "from dataset.aihub.hangul_real_image_dataset import *\n",
    "dataset = HangulRealImageDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HangulRealImage_BoxDetectionDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bbox': [[762, 306], [849, 306], [849, 518], [762, 518]], 'label': '소망'},\n",
       " {'bbox': [[754, 547], [837, 547], [837, 900], [754, 900]], 'label': '미용실'},\n",
       " {'bbox': [[730, 1053], [845, 1053], [845, 1147], [730, 1147]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[871, 1078], [1047, 1078], [1047, 1139], [871, 1139]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[1177, 732], [1479, 732], [1479, 794], [1177, 794]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[1429, 707], [1502, 707], [1502, 748], [1429, 748]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[1342, 1075], [1428, 1075], [1428, 1160], [1342, 1160]],\n",
       "  'label': 'xxx'},\n",
       " {'bbox': [[184, 345], [361, 345], [361, 611], [184, 611]], 'label': 'xxx'},\n",
       " {'bbox': [[121, 291], [184, 291], [184, 342], [121, 342]], 'label': 'xxx'},\n",
       " {'bbox': [[365, 194], [460, 194], [460, 252], [365, 252]], 'label': 'xxx'},\n",
       " {'bbox': [[391, 536], [443, 536], [443, 587], [391, 587]], 'label': 'xxx'},\n",
       " {'bbox': [[355, 610], [517, 610], [517, 684], [355, 684]], 'label': 'xxx'},\n",
       " {'bbox': [[172, 748], [240, 748], [240, 802], [172, 802]], 'label': 'xxx'},\n",
       " {'bbox': [[0, 168], [736, 168], [736, 1154], [0, 1154]], 'label': 'xxx'},\n",
       " {'bbox': [[998, 1], [1600, 1], [1600, 1092], [998, 1092]], 'label': 'xxx'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = dataset[0]\n",
    "dataset.show_xy(x, y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  step  acc  loss  precision  recall\n",
       "0    1.0   2.0  3.0   4.0        5.0     1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({\"epoch\":[], \"step\":[], \"acc\":[], \"loss\":[], \"precision\":[], \"recall\":[]})\n",
    "\n",
    "df = df._append({\"epoch\":1, \"step\":2, \"acc\":3, \"loss\":4, \"precision\":5, \"recall\":1}, ignore_index=True)\n",
    "df.to_csv(\"test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  step  acc  loss  precision  recall\n",
       "0    1.0   2.0  3.0   4.0        5.0     1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test.csv\", index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'det_MobileNet_sangmu',\n",
       " 'labelsets': ['sangmu'],\n",
       " 'model': 'MobileNetV3_large_x0_5',\n",
       " 'pretrained': True,\n",
       " 'train_config': './works/det_MobileNet_sangmu/train_config.yml',\n",
       " 'result_path': './works/det_MobileNet_sangmu/result.csv'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from database import *\n",
    "\n",
    "WorkDB().get_all_id()\n",
    "WorkDB().get_config(\"det_MobileNet_sangmu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import *\n",
    "\n",
    "WorkDB().get_all_id()\n",
    "# WorkDB().infer_det(\"det_MobileNet_sangmu\")\n",
    "# WorkDB().get_best_model_weight(\"det_MobileNet_sangmu\")\n",
    "# WorkDB().infer_det(\"det_MobileNet_sangmu\", \"test\", \"best\")\n",
    "WorkDB().infer_det(\"det_PPOCR_sangmu\", \"best\", \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"F:/5.SCI Lab/1.과제 & 연구/[2023] 불법옥외간판(외주)/데이터셋/레이블링 결과(최종)_0126/그외 간판\"\n",
    "\n",
    "wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[60, 140, 200]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_dir': './datasets',\n",
       " 'datasets': ['sangmu_std_MH', 'sangmu_std_DI', 'sangmu_std_DH'],\n",
       " 'infer': {'eval': ['eval_infer.txt'],\n",
       "  'test': ['test_infer.txt'],\n",
       "  'train': ['train_infer.txt']},\n",
       " 'label': {'eval': ['eval_label.txt'],\n",
       "  'test': ['test_label.txt'],\n",
       "  'train': ['train_label.txt']},\n",
       " 'seed': 100,\n",
       " 'split': {'sangmu_std_DH': [8, 1, 1],\n",
       "  'sangmu_std_DI': [8, 1, 1],\n",
       "  'sangmu_std_MH': [8, 1, 1]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"E:/workspace/paddleocr/labelsets/test1/config.yml\") as f:\n",
    "    x = yaml.load(f, Loader=yaml.FullLoader)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 10, 2: 20}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = {1:1, 2:2}\n",
    "y = {1:10, 2:20}\n",
    "\n",
    "x.update(y)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddlelabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
